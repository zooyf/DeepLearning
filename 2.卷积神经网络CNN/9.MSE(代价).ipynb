{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"index--container--2OwOl\"><div class=\"index--atom--lmAIo layout--content--3Smmq\"><div class=\"ltr\"><div class=\"ureact-markdown--markdown--3IhZa ureact-markdown \"><p>下面是我对 S 型函数的实现过程：</p>\n",
    "<pre><code><span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span> <span class=\"hljs-title\">Sigmoid</span><span class=\"hljs-params\">(Node)</span>:</span>\n",
    "    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">__init__</span><span class=\"hljs-params\">(self, node)</span>:</span>\n",
    "        Node.__init__(self, [node])\n",
    "\n",
    "    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">_sigmoid</span><span class=\"hljs-params\">(self, x)</span>:</span>\n",
    "        <span class=\"hljs-string\">\"\"\"\n",
    "        This method is separate from `forward` because it\n",
    "        will be used with `backward` as well.\n",
    "\n",
    "        `x`: A numpy array-like object.\n",
    "        \"\"\"</span>\n",
    "        <span class=\"hljs-keyword\">return</span> <span class=\"hljs-number\">1.</span> / (<span class=\"hljs-number\">1.</span> + np.exp(-x)) <span class=\"hljs-comment\"># the `.` ensures that `1` is a float</span>\n",
    "\n",
    "    <span class=\"hljs-function\"><span class=\"hljs-keyword\">def</span> <span class=\"hljs-title\">forward</span><span class=\"hljs-params\">(self)</span>:</span>\n",
    "        input_value = self.inbound_nodes[<span class=\"hljs-number\">0</span>].value\n",
    "        self.value = self._sigmoid(input_value)\n",
    "</code></pre><p>你可能觉得奇怪，为何 <code>_sigmoid</code> 具有单独的方法。正如在 S 型函数（等式 (4)）的导数中看到的，S 型函数实际上是<em>它自己的导数的一部分</em>。将 <code>_sigmoid</code> 分离出来意味着你不需要为前向传播和反向传播实现两次。</p>\n",
    "<p>这很不错！此时，你已经使用了权重和偏置来计算输出。并且你使用了激活函数来对输出进行分类。你可能还记得，神经网络通过修改权重和偏置（根据标签化的数据集进行训练）改善输出的<strong>精确度</strong>。</p>\n",
    "</div></div><span></span></div><div class=\"index--instructor-notes-container--24U8Y shared--outer-container--3eppq\"><div class=\"index--instructor-notes--39nNE layout--content--3Smmq\"><div><noscript></noscript></div></div></div></div><div class=\"index--container--2OwOl\"><div class=\"index--atom--lmAIo layout--content--3Smmq\"><div class=\"ltr\"><div class=\"ureact-markdown--markdown--3IhZa ureact-markdown \"><p>我们可以采用多种技巧来定义神经网络的精确度，所有技巧围绕的都是神经网络是否能够生成与已知正确的值非常接近的值。人们用不同的名称来表示这一精确度测量者，通常称之为<strong>损失</strong>或<strong>代价</strong>。我将经常使用<em>代价</em>一词。</p>\n",
    "<p>对于本测验，你将使用均方差 (MSE) 计算代价。如下所示：</p>\n",
    "</div></div><span></span></div><div class=\"index--instructor-notes-container--24U8Y shared--outer-container--3eppq\"><div class=\"index--instructor-notes--39nNE layout--content--3Smmq\"><div><noscript></noscript></div></div></div></div><div class=\"index--container--2OwOl\"><div class=\"index--atom--lmAIo layout--content--3Smmq\"><div class=\"ltr\"><div class=\"ureact-markdown--markdown--3IhZa ureact-markdown \"><p></p><div id=\"container\" style=\"text-align: center\">\n",
    "    <span class=\"mathquill\" style=\"font-size: 16pt\"><span class=\"katex\"><span class=\"katex-mathml\"><math><semantics><mrow><mi>C</mi><mo>(</mo><mi>w</mi><mo separator=\"true\">,</mo><mi>b</mi><mo>)</mo><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>m</mi></mrow></mfrac><msub><mo>∑</mo><mi>x</mi></msub><mi mathvariant=\"normal\">∣</mi><mi mathvariant=\"normal\">∣</mi><mi>y</mi><mo>(</mo><mi>x</mi><mo>)</mo><mo>−</mo><mi>a</mi><mi mathvariant=\"normal\">∣</mi><msup><mi mathvariant=\"normal\">∣</mi><mn>2</mn></msup></mrow><annotation encoding=\"application/x-tex\">\n",
    "        C(w, b) = \\frac{1}{m}\\sum_x || y(x) -  a   || ^2\n",
    "    </annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height: 0.845108em;\"></span><span class=\"strut bottom\" style=\"height: 1.19011em; vertical-align: -0.345em;\"></span><span class=\"base textstyle uncramped\"><span class=\"mord mathit\" style=\"margin-right: 0.07153em;\">C</span><span class=\"mopen\">(</span><span class=\"mord mathit\" style=\"margin-right: 0.02691em;\">w</span><span class=\"mpunct\">,</span><span class=\"mord mathit\">b</span><span class=\"mclose\">)</span><span class=\"mrel\">=</span><span class=\"mord reset-textstyle textstyle uncramped\"><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist\"><span class=\"\" style=\"top: 0.345em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span class=\"\" style=\"font-size: 0em;\">&#8203;</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord scriptstyle cramped\"><span class=\"mord mathit\">m</span></span></span></span><span class=\"\" style=\"top: -0.23em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span class=\"\" style=\"font-size: 0em;\">&#8203;</span></span><span class=\"reset-textstyle textstyle uncramped frac-line\"></span></span><span class=\"\" style=\"top: -0.394em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span class=\"\" style=\"font-size: 0em;\">&#8203;</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord scriptstyle uncramped\"><span class=\"mord mathrm\">1</span></span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span class=\"\" style=\"font-size: 0em;\">&#8203;</span></span>&#8203;</span></span></span><span class=\"sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter\"></span></span><span class=\"mop\"><span class=\"op-symbol small-op mop\" style=\"top: -5e-06em;\">∑</span><span class=\"vlist\"><span class=\"\" style=\"top: 0.30001em; margin-right: 0.05em; margin-left: 0em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span class=\"\" style=\"font-size: 0em;\">&#8203;</span></span><span class=\"reset-textstyle scriptstyle cramped\"><span class=\"mord mathit\">x</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span class=\"\" style=\"font-size: 0em;\">&#8203;</span></span>&#8203;</span></span></span><span class=\"mord mathrm\">∣</span><span class=\"mord mathrm\">∣</span><span class=\"mord mathit\" style=\"margin-right: 0.03588em;\">y</span><span class=\"mopen\">(</span><span class=\"mord mathit\">x</span><span class=\"mclose\">)</span><span class=\"mbin\">−</span><span class=\"mord mathit\">a</span><span class=\"mord mathrm\">∣</span><span class=\"mord\"><span class=\"mord mathrm\">∣</span><span class=\"vlist\"><span class=\"\" style=\"top: -0.363em; margin-right: 0.05em;\"><span class=\"fontsize-ensurer reset-size5 size5\"><span class=\"\" style=\"font-size: 0em;\">&#8203;</span></span><span class=\"reset-textstyle scriptstyle uncramped\"><span class=\"mord mathrm\">2</span></span></span><span class=\"baseline-fix\"><span class=\"fontsize-ensurer reset-size5 size5\"><span class=\"\" style=\"font-size: 0em;\">&#8203;</span></span>&#8203;</span></span></span></span></span></span></span><p></p>\n",
    "<p>等式 (5)</p>\n",
    "<div id=\"container\"></div></div></div></div><span></span></div><div class=\"index--instructor-notes-container--24U8Y shared--outer-container--3eppq\"><div class=\"index--instructor-notes--39nNE layout--content--3Smmq\"><div><noscript></noscript></div></div></div></div><div class=\"index--container--2OwOl\"><div class=\"index--atom--lmAIo layout--content--3Smmq\"><div class=\"ltr\"><div class=\"ureact-markdown--markdown--3IhZa ureact-markdown \"><p>此处，<em>w</em> 表示网络中所有的权重集合，<em>b</em> 表示所有的偏置，<em>m</em> 表示训练示例的总数，<em>a</em> 是 <em>y(x)</em> 的近视值，<em>a</em> 和 <em>y(x)</em> 都是长度相同的向量。</p>\n",
    "<p>权重集合是所有权重矩阵压平成的向量，串联成一个大的向量。偏置也相似，但是它们已经是向量，所以在串联前不需要压平。</p>\n",
    "<p>以下是创建 <em>w</em> 的代码示例：</p>\n",
    "<pre><code class=\"lang-python\"><span class=\"hljs-comment\"># 2 by 2 matrices</span>\n",
    "w1  = np.array([[<span class=\"hljs-number\">1</span>, <span class=\"hljs-number\">2</span>], [<span class=\"hljs-number\">3</span>, <span class=\"hljs-number\">4</span>]])\n",
    "w2  = np.array([[<span class=\"hljs-number\">5</span>, <span class=\"hljs-number\">6</span>], [<span class=\"hljs-number\">7</span>, <span class=\"hljs-number\">8</span>]])\n",
    "\n",
    "<span class=\"hljs-comment\"># flatten</span>\n",
    "w1_flat = np.reshape(w1, -<span class=\"hljs-number\">1</span>)\n",
    "w2_flat = np.reshape(w2, -<span class=\"hljs-number\">1</span>)\n",
    "\n",
    "w = np.concatenate((w1_flat, w2_flat))\n",
    "<span class=\"hljs-comment\"># array([1, 2, 3, 4, 5, 6, 7, 8])</span>\n",
    "</code></pre>\n",
    "<p>这样可以轻松地将神经网络中使用的所有权重和偏置提取出来，从而更轻松地编写代码，我们将在接下来的梯度下降部分看到。</p>\n",
    "<p><strong>注意：</strong>你不需要在你的代码中实现！只是将权重和偏置看做集合比单独对待更容易处理。</p>\n",
    "<p>代价 <em>C</em> 取决于正确输出 <em>y(x)</em> 和网络的输出 <em>a</em> 之间的差值。很容易看出 <em>y(x)</em> 和 <em>a</em> (对于 <em>x</em> 的所有值）) 之间的差始终不为 0。</p>\n",
    "<p>这是理想情况，实际上学习流程就是为了尽量减小代价。</p>\n",
    "<p>现在请你来计算代价。</p>\n",
    "<p>你在上道测验的前向中实现了这一网络。</p>\n",
    "<p>现在可以看出它输出的是无用数据。S 型节点的激活什么也没表示，因为该网络没有可以与之对比的带标签输出。此外，权重和偏置无法更改，没有代价的话，无法进行学习。</p>\n",
    "<h3 id=\"-\">说明</h3>\n",
    "<p>对于这道测验，你将对 nn.py 中的网络运行前向传递。请完成 <code>MSE</code> 方法的实现，使其能够根据上述等式计算代价。</p>\n",
    "<p>建议使用 <code>np.square</code> (<a target=\"_blank\" href=\"https://docs.scipy.org/doc/numpy/reference/generated/numpy.square.html\">文档</a>) 方法，这样代码编写起来更轻松。</p>\n",
    "<ol>\n",
    "<li>查看 nn.py，看看 <code>MSE</code> 将如何计算代价。</li>\n",
    "<li>打开 miniflow.py. 完成 <code>MSE</code> 的构建。</li>\n",
    "<li>测试你的网络！通过 nn.py 并根据输入判断代价是否合理。</li>\n",
    "</ol>\n",
    "</div></div><span></span></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.4166666667\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test your MSE method with this script!\n",
    "\n",
    "No changes necessary, but feel free to play\n",
    "with this script to test your network.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from miniflow import *\n",
    "\n",
    "y, a = Input(), Input()\n",
    "cost = MSE(y, a)\n",
    "\n",
    "y_ = np.array([1, 2, 3])\n",
    "a_ = np.array([4.5, 5, 10])\n",
    "\n",
    "feed_dict = {y: y_, a: a_}\n",
    "graph = topological_sort(feed_dict)\n",
    "# forward pass\n",
    "forward_pass(graph)\n",
    "\n",
    "\"\"\"\n",
    "Expected output\n",
    "\n",
    "23.4166666667\n",
    "\"\"\"\n",
    "print(cost.value)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
